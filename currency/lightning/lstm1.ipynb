{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "import lightning as L\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../cleaned/usdrub_new.csv')\n",
    "columns = ['close']\n",
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_length = math.floor(len(df) * 0.7)\n",
    "train_df, test_df = df.iloc[:training_length], df.iloc[training_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CurrencyDataset import CurrencyDataset\n",
    "train_data = CurrencyDataset(train_df,  seq_length = 5)\n",
    "test_data = CurrencyDataset(test_df,  seq_length = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_data, batch_size=8)\n",
    "test_dl = DataLoader(test_data, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "torch.Size([8, 5, 1])\n",
      "torch.Size([8, 1])\n"
     ]
    }
   ],
   "source": [
    "print('Training Set:')\n",
    "for sample in train_dl:  \n",
    "    print(sample[0].size())\n",
    "    print(sample[1].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(L.LightningModule):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.lstm = nn.LSTM(input_size=1, hidden_size=1, batch_first=True)\n",
    "    self.linear = nn.Linear(in_features=1, out_features=1)\n",
    "\n",
    "    self.example_input_array = torch.Tensor(8, 5, 1)\n",
    "\n",
    "  def forward(self, input):\n",
    "    lstm_output = self.lstm(input)\n",
    "    \n",
    "    # [batch_size, 1]\n",
    "    last_unrolled_values = lstm_output[0][:, -1, :]\n",
    "    prediction = self.linear(last_unrolled_values)\n",
    "    return prediction\n",
    "  \n",
    "  def configure_optimizers(self):\n",
    "    return Adam(self.parameters(), lr= 0.01)\n",
    "  \n",
    "  def training_step(self, batch, batch_idx):\n",
    "    input = batch[0]\n",
    "    label = batch[1]\n",
    "    # [batch_size, 1]\n",
    "    output = self.forward(input)\n",
    "    loss = (output - label).pow(2).sum()\n",
    "\n",
    "    self.log(\"train_loss\", loss)\n",
    "    return loss\n",
    "  \n",
    "  def test_step(self, batch, batch_idx):\n",
    "    input = batch[0]\n",
    "    label = batch[1]\n",
    "    # [batch_size, 1]\n",
    "    output = self.forward(input)\n",
    "    loss = (output - label).pow(2).sum()\n",
    "\n",
    "    self.log(\"test_loss\", loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningLSTM(L.LightningModule):\n",
    "  def __init__(self, lstm, learning_rate):\n",
    "    super().__init__()\n",
    "    self.lstm = lstm\n",
    "    self.learning_rate = learning_rate\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    return Adam(self.parameters(), lr= self.learning_rate)\n",
    "  \n",
    "  def training_step(self, batch, batch_idx):\n",
    "    input = batch[0]\n",
    "    label = batch[1]\n",
    "    # [batch_size, 1]\n",
    "    output = self.lstm(input)\n",
    "    loss = (output - label).pow(2).sum()\n",
    "\n",
    "    self.log(\"train_loss\", loss)\n",
    "    return loss\n",
    "  \n",
    "  def test_step(self, batch, batch_idx):\n",
    "    input = batch[0]\n",
    "    label = batch[1]\n",
    "    # [batch_size, 1]\n",
    "    output = self.lstm(input)\n",
    "    loss = (output - label).pow(2).sum()\n",
    "\n",
    "    self.log(\"test_loss\", loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs = 50, log_every_n_steps=2, profiler=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type   | Params | In sizes  | Out sizes                          \n",
      "------------------------------------------------------------------------------------\n",
      "0 | lstm   | LSTM   | 16     | [8, 5, 1] | [[8, 5, 1], [[1, 8, 1], [1, 8, 1]]]\n",
      "1 | linear | Linear | 2      | [8, 1]    | [8, 1]                             \n",
      "------------------------------------------------------------------------------------\n",
      "18        Trainable params\n",
      "0         Non-trainable params\n",
      "18        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "c:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 273/273 [00:01<00:00, 215.76it/s, v_num=13]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 273/273 [00:01<00:00, 214.74it/s, v_num=13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Action                                                                                                                                                        \t|  Mean duration (s)\t|  Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Total                                                                                                                                                         \t|  -              \t|  492082         \t|  63.656         \t|  100 %          \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  run_training_epoch                                                                                                                                            \t|  1.2406         \t|  50             \t|  62.031         \t|  97.447         \t|\n",
      "|  run_training_batch                                                                                                                                            \t|  0.0017388      \t|  13650          \t|  23.734         \t|  37.285         \t|\n",
      "|  [LightningModule]LSTM.optimizer_step                                                                                                                          \t|  0.001699       \t|  13650          \t|  23.191         \t|  36.432         \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_end                                                                                                                  \t|  0.00090117     \t|  13650          \t|  12.301         \t|  19.324         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.backward                                                                                                                       \t|  0.00064615     \t|  13650          \t|  8.82           \t|  13.856         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.training_step                                                                                                                  \t|  0.00051055     \t|  13650          \t|  6.969          \t|  10.948         \t|\n",
      "|  [_TrainingEpochLoop].train_dataloader_next                                                                                                                    \t|  0.00046718     \t|  13650          \t|  6.377          \t|  10.018         \t|\n",
      "|  [LightningModule]LSTM.optimizer_zero_grad                                                                                                                     \t|  8.4103e-05     \t|  13650          \t|  1.148          \t|  1.8034         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.batch_to_device                                                                                                                \t|  5.4725e-05     \t|  13650          \t|  0.747          \t|  1.1735         \t|\n",
      "|  [LightningModule]LSTM.transfer_batch_to_device                                                                                                                \t|  4.4392e-05     \t|  13651          \t|  0.606          \t|  0.95199        \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_end      \t|  0.00314        \t|  50             \t|  0.157          \t|  0.24664        \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_end      \t|  1.1355e-05     \t|  13650          \t|  0.155          \t|  0.2435         \t|\n",
      "|  [LightningModule]LSTM.configure_gradient_clipping                                                                                                             \t|  1.011e-05      \t|  13650          \t|  0.138          \t|  0.21679        \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_start                                                                                                                \t|  0.00094        \t|  50             \t|  0.047          \t|  0.073834       \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_start                                                                                                                \t|  3.37e-06       \t|  13650          \t|  0.046          \t|  0.072263       \t|\n",
      "|  [Callback]ModelSummary.on_after_backward                                                                                                                      \t|  2.3443e-06     \t|  13650          \t|  0.032          \t|  0.05027        \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_end                                                                                                                     \t|  2.3443e-06     \t|  13650          \t|  0.032          \t|  0.05027        \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_optimizer_step                                                                                                            \t|  2.1978e-06     \t|  13650          \t|  0.03           \t|  0.047128       \t|\n",
      "|  [LightningModule]LSTM.on_before_batch_transfer                                                                                                                \t|  1.1721e-06     \t|  13651          \t|  0.016          \t|  0.025135       \t|\n",
      "|  [Callback]ModelSummary.on_fit_start                                                                                                                           \t|  0.016          \t|  1              \t|  0.016          \t|  0.025135       \t|\n",
      "|  [Callback]ModelSummary.on_before_zero_grad                                                                                                                    \t|  1.1722e-06     \t|  13650          \t|  0.016          \t|  0.025135       \t|\n",
      "|  [Callback]ModelSummary.on_before_backward                                                                                                                     \t|  1.1722e-06     \t|  13650          \t|  0.016          \t|  0.025135       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_backward      \t|  1.1722e-06     \t|  13650          \t|  0.016          \t|  0.025135       \t|\n",
      "|  [Callback]TQDMProgressBar.on_after_backward                                                                                                                   \t|  1.0989e-06     \t|  13650          \t|  0.015          \t|  0.023564       \t|\n",
      "|  [LightningModule]LSTM.on_train_batch_end                                                                                                                      \t|  1.0989e-06     \t|  13650          \t|  0.015          \t|  0.023564       \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_end                                                                                                                  \t|  0.0003         \t|  50             \t|  0.015          \t|  0.023564       \t|\n",
      "|  [LightningModule]LSTM.configure_callbacks                                                                                                                     \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.prepare_data                                                                                                                            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.setup                                                                                                                               \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.setup                                                                                                                                  \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.setup                   \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.setup                                                                                                                                   \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.configure_optimizers                                                                                                                    \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_start                                                                                                                        \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_after_batch_transfer                                                                                                                 \t|  0.0            \t|  13651          \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_start            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_fit_start                                                                                                                            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_start                                                                                                                      \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_start                                                                                                                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_start          \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_train_start                                                                                                                          \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_start                                                                                                                 \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_start                                                                                                                   \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_start    \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_train_epoch_start                                                                                                                    \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_start                                                                                                                   \t|  0.0            \t|  13650          \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_start    \t|  0.0            \t|  13650          \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_train_batch_start                                                                                                                    \t|  0.0            \t|  13650          \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_batch_start                                                                                                           \t|  0.0            \t|  13650          \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_zero_grad                                                                                                                 \t|  0.0            \t|  13650          \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_zero_grad     \t|  0.0            \t|  13650          \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_before_zero_grad                                                                                                                     \t|  0.0            \t|  13650          \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_backward                                                                                                                  \t|  0.0            \t|  13650          \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_before_backward                                                                                                                      \t|  0.0            \t|  13650          \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_after_backward       \t|  0.0            \t|  13650          \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_after_backward                                                                                                                       \t|  0.0            \t|  13650          \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_before_optimizer_step                                                                                                               \t|  0.0            \t|  13650          \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_optimizer_step\t|  0.0            \t|  13650          \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_before_optimizer_step                                                                                                                \t|  0.0            \t|  13650          \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_end                                                                                                                     \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_train_epoch_end                                                                                                                      \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_save_checkpoint                                                                                                                  \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_save_checkpoint                                                                                                                     \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_save_checkpoint      \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_save_checkpoint                                                                                                                      \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_end                                                                                                                        \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_end                                                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_end            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_train_end                                                                                                                            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_end                                                                                                                   \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_end                                                                                                                          \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_fit_end                                                                                                                             \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_end              \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_fit_end                                                                                                                              \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.teardown                                                                                                                            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.teardown                                                                                                                               \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.teardown                \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.teardown                                                                                                                                \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloaders=train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 117/117 [00:00<00:00, 583.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      2404.7880859375      </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     2404.7880859375     \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 2404.7880859375}]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, dataloaders = test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training some more\n",
    "path_to_best_checkpoint = trainer.checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at c:\\Users\\igor\\Documents\\GitHub\\financial_tools\\currency\\lightning\\lightning_logs\\version_10\\checkpoints\\epoch=29-step=8190.ckpt\n",
      "c:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:361: The dirpath has changed from 'c:\\\\Users\\\\igor\\\\Documents\\\\GitHub\\\\financial_tools\\\\currency\\\\lightning\\\\lightning_logs\\\\version_10\\\\checkpoints' to 'c:\\\\Users\\\\igor\\\\Documents\\\\GitHub\\\\financial_tools\\\\currency\\\\lightning\\\\lightning_logs\\\\version_11\\\\checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | lstm | LSTM | 18    \n",
      "------------------------------\n",
      "18        Trainable params\n",
      "0         Non-trainable params\n",
      "18        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "Restored all states from the checkpoint at c:\\Users\\igor\\Documents\\GitHub\\financial_tools\\currency\\lightning\\lightning_logs\\version_10\\checkpoints\\epoch=29-step=8190.ckpt\n",
      "c:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 273/273 [00:01<00:00, 259.55it/s, v_num=11]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 273/273 [00:01<00:00, 258.57it/s, v_num=11]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloaders=train_dl, ckpt_path = path_to_best_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 18632), started 16:06:35 ago. (Use '!kill 18632' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-88a2ccd702da0795\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-88a2ccd702da0795\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | Name   | Type   | Params | In sizes  | Out sizes                          \n",
      "------------------------------------------------------------------------------------\n",
      "0 | lstm   | LSTM   | 16     | [8, 5, 1] | [[8, 5, 1], [[1, 8, 1], [1, 8, 1]]]\n",
      "1 | linear | Linear | 2      | [8, 1]    | [8, 1]                             \n",
      "------------------------------------------------------------------------------------\n",
      "18        Trainable params\n",
      "0         Non-trainable params\n",
      "18        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.utilities.model_summary import ModelSummary\n",
    "summary = ModelSummary(model, max_depth=-1)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "input = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size=1, hidden_size=1, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_output = lstm(input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 5, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_output[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_unrolled_values = lstm_output[0][:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_unrolled_values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(in_features=1, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_output = linear(last_unrolled_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_output.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
