{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "import lightning as L\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../cleaned/usdrub_new.csv')\n",
    "columns = ['close']\n",
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_length = math.floor(len(df) * 0.7)\n",
    "train_df, test_df = df.iloc[:training_length], df.iloc[training_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CurrencyDataset import CurrencyDataset\n",
    "train_data = CurrencyDataset(train_df,  seq_length = 5)\n",
    "test_data = CurrencyDataset(test_df,  seq_length = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_data, batch_size=8)\n",
    "test_dl = DataLoader(test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CurrencyDataModule import CurrencyDataModule\n",
    "dm = CurrencyDataModule('../cleaned/usdrub_new.csv', seq_length=5, columns=['close'], batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "torch.Size([8, 5, 1])\n",
      "torch.Size([8, 1])\n"
     ]
    }
   ],
   "source": [
    "print('Training Set:')\n",
    "for sample in train_dl:  \n",
    "    print(sample[0].size())\n",
    "    print(sample[1].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(L.LightningModule):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.lstm = nn.LSTM(input_size=1, hidden_size=1, batch_first=True)\n",
    "    self.linear = nn.Linear(in_features=1, out_features=1)\n",
    "\n",
    "    self.example_input_array = torch.Tensor(8, 5, 1)\n",
    "\n",
    "  def forward(self, input):\n",
    "    lstm_output = self.lstm(input)\n",
    "    \n",
    "    # [batch_size, 1]\n",
    "    last_unrolled_values = lstm_output[0][:, -1, :]\n",
    "    prediction = self.linear(last_unrolled_values)\n",
    "    return prediction\n",
    "  \n",
    "  def configure_optimizers(self):\n",
    "    return Adam(self.parameters(), lr= 0.01)\n",
    "  \n",
    "  def training_step(self, batch, batch_idx):\n",
    "    input = batch[0]\n",
    "    label = batch[1]\n",
    "    # [batch_size, 1]\n",
    "    output = self.forward(input)\n",
    "    loss = (output - label).pow(2).sum()\n",
    "\n",
    "    self.log(\"train_loss\", loss)\n",
    "    return loss\n",
    "  \n",
    "  def test_step(self, batch, batch_idx):\n",
    "    input = batch[0]\n",
    "    label = batch[1]\n",
    "    # [batch_size, 1]\n",
    "    output = self.forward(input)\n",
    "    loss = (output - label).pow(2).sum()\n",
    "\n",
    "    self.log(\"test_loss\", loss)\n",
    "    return loss\n",
    "  \n",
    "  def predict_step(self, batch, batch_idx):\n",
    "    return self.forward(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningLSTM(L.LightningModule):\n",
    "  def __init__(self, lstm, learning_rate):\n",
    "    super().__init__()\n",
    "    self.lstm = lstm\n",
    "    self.learning_rate = learning_rate\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    return Adam(self.parameters(), lr= self.learning_rate)\n",
    "  \n",
    "  def training_step(self, batch, batch_idx):\n",
    "    input = batch[0]\n",
    "    label = batch[1]\n",
    "    # [batch_size, 1]\n",
    "    output = self.lstm(input)\n",
    "    loss = (output - label).pow(2).sum()\n",
    "\n",
    "    self.log(\"train_loss\", loss)\n",
    "    return loss\n",
    "  \n",
    "  def test_step(self, batch, batch_idx):\n",
    "    input = batch[0]\n",
    "    label = batch[1]\n",
    "    # [batch_size, 1]\n",
    "    output = self.lstm(input)\n",
    "    loss = (output - label).pow(2).sum()\n",
    "\n",
    "    self.log(\"test_loss\", loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs = 50, log_every_n_steps=2, profiler=\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type   | Params | In sizes  | Out sizes                          \n",
      "------------------------------------------------------------------------------------\n",
      "0 | lstm   | LSTM   | 16     | [8, 5, 1] | [[8, 5, 1], [[1, 8, 1], [1, 8, 1]]]\n",
      "1 | linear | Linear | 2      | [8, 1]    | [8, 1]                             \n",
      "------------------------------------------------------------------------------------\n",
      "18        Trainable params\n",
      "0         Non-trainable params\n",
      "18        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "c:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 137/137 [00:00<00:00, 209.93it/s, v_num=15]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 137/137 [00:00<00:00, 208.34it/s, v_num=15]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Action                                                                                                                                                        \t|  Mean duration (s)\t|  Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Total                                                                                                                                                         \t|  -              \t|  247336         \t|  46.375         \t|  100 %          \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  run_training_epoch                                                                                                                                            \t|  0.66472        \t|  50             \t|  33.236         \t|  71.668         \t|\n",
      "|  run_training_batch                                                                                                                                            \t|  0.0017285      \t|  6850           \t|  11.84          \t|  25.531         \t|\n",
      "|  [LightningModule]LSTM.optimizer_step                                                                                                                          \t|  0.0016959      \t|  6850           \t|  11.617         \t|  25.05          \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_end                                                                                                                  \t|  0.0009746      \t|  6850           \t|  6.676          \t|  14.396         \t|\n",
      "|  [_TrainingEpochLoop].train_dataloader_next                                                                                                                    \t|  0.00071387     \t|  6850           \t|  4.89           \t|  10.544         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.backward                                                                                                                       \t|  0.00066292     \t|  6850           \t|  4.541          \t|  9.7919         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.training_step                                                                                                                  \t|  0.00049971     \t|  6850           \t|  3.423          \t|  7.3811         \t|\n",
      "|  [LightningModule]LSTM.optimizer_zero_grad                                                                                                                     \t|  0.0001165      \t|  6850           \t|  0.798          \t|  1.7208         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.batch_to_device                                                                                                                \t|  6.8905e-05     \t|  6850           \t|  0.472          \t|  1.0178         \t|\n",
      "|  [LightningModule]LSTM.transfer_batch_to_device                                                                                                                \t|  4.5979e-05     \t|  6851           \t|  0.315          \t|  0.67925        \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_end      \t|  0.00248        \t|  50             \t|  0.124          \t|  0.26739        \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_end      \t|  1.1679e-05     \t|  6850           \t|  0.08           \t|  0.17251        \t|\n",
      "|  [LightningModule]LSTM.configure_gradient_clipping                                                                                                             \t|  9.1971e-06     \t|  6850           \t|  0.063          \t|  0.13585        \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_start                                                                                                                \t|  0.00122        \t|  50             \t|  0.061          \t|  0.13154        \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_end                                                                                                                  \t|  0.00064        \t|  50             \t|  0.032          \t|  0.069003       \t|\n",
      "|  [Callback]ModelSummary.on_fit_start                                                                                                                           \t|  0.016          \t|  1              \t|  0.016          \t|  0.034501       \t|\n",
      "|  [Callback]ModelSummary.on_before_zero_grad                                                                                                                    \t|  2.3358e-06     \t|  6850           \t|  0.016          \t|  0.034501       \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_end                                                                                                                     \t|  0.00032        \t|  50             \t|  0.016          \t|  0.034501       \t|\n",
      "|  [LightningModule]LSTM.on_after_batch_transfer                                                                                                                 \t|  2.1895e-06     \t|  6851           \t|  0.015          \t|  0.032345       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_start    \t|  2.1898e-06     \t|  6850           \t|  0.015          \t|  0.032345       \t|\n",
      "|  [LightningModule]LSTM.on_after_backward                                                                                                                       \t|  2.1898e-06     \t|  6850           \t|  0.015          \t|  0.032345       \t|\n",
      "|  [Callback]ModelSummary.on_before_optimizer_step                                                                                                               \t|  2.1898e-06     \t|  6850           \t|  0.015          \t|  0.032345       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_optimizer_step\t|  2.1898e-06     \t|  6850           \t|  0.015          \t|  0.032345       \t|\n",
      "|  [LightningModule]LSTM.configure_callbacks                                                                                                                     \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningDataModule]CurrencyDataModule.prepare_data                                                                                                          \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.prepare_data                                                                                                                            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningDataModule]CurrencyDataModule.setup                                                                                                                 \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.setup                                                                                                                               \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.setup                                                                                                                                  \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.setup                   \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.setup                                                                                                                                   \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.configure_optimizers                                                                                                                    \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_start                                                                                                                        \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_before_batch_transfer                                                                                                                \t|  0.0            \t|  6851           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_start            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_fit_start                                                                                                                            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningDataModule]CurrencyDataModule.train_dataloader                                                                                                      \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_start                                                                                                                      \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_start                                                                                                                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_start          \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_train_start                                                                                                                          \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_start                                                                                                                 \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_start                                                                                                                   \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_start    \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_train_epoch_start                                                                                                                    \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_start                                                                                                                \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_start                                                                                                                   \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_train_batch_start                                                                                                                    \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_batch_start                                                                                                           \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_zero_grad                                                                                                                 \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_zero_grad     \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_before_zero_grad                                                                                                                     \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_backward                                                                                                                  \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_before_backward                                                                                                                     \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_backward      \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_before_backward                                                                                                                      \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_after_backward                                                                                                                   \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_after_backward                                                                                                                      \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_after_backward       \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_optimizer_step                                                                                                            \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_before_optimizer_step                                                                                                                \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_end                                                                                                                     \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_train_batch_end                                                                                                                      \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_train_epoch_end                                                                                                                      \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningDataModule]CurrencyDataModule.state_dict                                                                                                            \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_save_checkpoint                                                                                                                  \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_save_checkpoint                                                                                                                     \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_save_checkpoint      \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_save_checkpoint                                                                                                                      \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_end                                                                                                                        \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_end                                                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_end            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_train_end                                                                                                                            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_end                                                                                                                   \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_end                                                                                                                          \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_fit_end                                                                                                                             \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_end              \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_fit_end                                                                                                                              \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningDataModule]CurrencyDataModule.teardown                                                                                                              \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.teardown                                                                                                                            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.teardown                                                                                                                               \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.teardown                \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.teardown                                                                                                                                \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 59/59 [00:00<00:00, 379.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     10685.3388671875      </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    10685.3388671875     \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TEST Profiler Report\n",
      "\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Action                                                                                                                                                        \t|  Mean duration (s)\t|  Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Total                                                                                                                                                         \t|  -              \t|  248195         \t|  62.672         \t|  100 %          \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  run_training_epoch                                                                                                                                            \t|  0.66472        \t|  50             \t|  33.236         \t|  53.032         \t|\n",
      "|  run_training_batch                                                                                                                                            \t|  0.0017285      \t|  6850           \t|  11.84          \t|  18.892         \t|\n",
      "|  [LightningModule]LSTM.optimizer_step                                                                                                                          \t|  0.0016959      \t|  6850           \t|  11.617         \t|  18.536         \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_end                                                                                                                  \t|  0.0009746      \t|  6850           \t|  6.676          \t|  10.652         \t|\n",
      "|  [_TrainingEpochLoop].train_dataloader_next                                                                                                                    \t|  0.00071387     \t|  6850           \t|  4.89           \t|  7.8025         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.backward                                                                                                                       \t|  0.00066292     \t|  6850           \t|  4.541          \t|  7.2457         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.training_step                                                                                                                  \t|  0.00049971     \t|  6850           \t|  3.423          \t|  5.4618         \t|\n",
      "|  [LightningModule]LSTM.optimizer_zero_grad                                                                                                                     \t|  0.0001165      \t|  6850           \t|  0.798          \t|  1.2733         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.batch_to_device                                                                                                                \t|  6.8317e-05     \t|  6909           \t|  0.472          \t|  0.75313        \t|\n",
      "|  [LightningModule]LSTM.transfer_batch_to_device                                                                                                                \t|  4.5586e-05     \t|  6910           \t|  0.315          \t|  0.50262        \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_end      \t|  0.00248        \t|  50             \t|  0.124          \t|  0.19786        \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_end      \t|  1.1679e-05     \t|  6850           \t|  0.08           \t|  0.12765        \t|\n",
      "|  [_EvaluationLoop].test_next                                                                                                                                   \t|  0.0013051      \t|  59             \t|  0.077          \t|  0.12286        \t|\n",
      "|  [LightningModule]LSTM.configure_gradient_clipping                                                                                                             \t|  9.1971e-06     \t|  6850           \t|  0.063          \t|  0.10052        \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_start                                                                                                                \t|  0.00122        \t|  50             \t|  0.061          \t|  0.097332       \t|\n",
      "|  [Callback]TQDMProgressBar.on_test_batch_end                                                                                                                   \t|  0.00079661     \t|  59             \t|  0.047          \t|  0.074994       \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_end                                                                                                                  \t|  0.00064        \t|  50             \t|  0.032          \t|  0.051059       \t|\n",
      "|  [Strategy]SingleDeviceStrategy.test_step                                                                                                                      \t|  0.00054237     \t|  59             \t|  0.032          \t|  0.051059       \t|\n",
      "|  [Callback]ModelSummary.on_fit_start                                                                                                                           \t|  0.016          \t|  1              \t|  0.016          \t|  0.02553        \t|\n",
      "|  [Callback]ModelSummary.on_before_zero_grad                                                                                                                    \t|  2.3358e-06     \t|  6850           \t|  0.016          \t|  0.02553        \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_end                                                                                                                     \t|  0.00032        \t|  50             \t|  0.016          \t|  0.02553        \t|\n",
      "|  [LightningModule]LSTM.on_after_batch_transfer                                                                                                                 \t|  2.1708e-06     \t|  6910           \t|  0.015          \t|  0.023934       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_start    \t|  2.1898e-06     \t|  6850           \t|  0.015          \t|  0.023934       \t|\n",
      "|  [LightningModule]LSTM.on_after_backward                                                                                                                       \t|  2.1898e-06     \t|  6850           \t|  0.015          \t|  0.023934       \t|\n",
      "|  [Callback]ModelSummary.on_before_optimizer_step                                                                                                               \t|  2.1898e-06     \t|  6850           \t|  0.015          \t|  0.023934       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_optimizer_step\t|  2.1898e-06     \t|  6850           \t|  0.015          \t|  0.023934       \t|\n",
      "|  [LightningModule]LSTM.configure_callbacks                                                                                                                     \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningDataModule]CurrencyDataModule.prepare_data                                                                                                          \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.prepare_data                                                                                                                            \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningDataModule]CurrencyDataModule.setup                                                                                                                 \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.setup                                                                                                                               \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.setup                                                                                                                                  \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.setup                   \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.setup                                                                                                                                   \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.configure_optimizers                                                                                                                    \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_start                                                                                                                        \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_before_batch_transfer                                                                                                                \t|  0.0            \t|  6910           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_start            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_fit_start                                                                                                                            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningDataModule]CurrencyDataModule.train_dataloader                                                                                                      \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_start                                                                                                                      \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_start                                                                                                                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_start          \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_train_start                                                                                                                          \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_start                                                                                                                 \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_start                                                                                                                   \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_start    \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_train_epoch_start                                                                                                                    \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_start                                                                                                                \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_start                                                                                                                   \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_train_batch_start                                                                                                                    \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_batch_start                                                                                                           \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_zero_grad                                                                                                                 \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_zero_grad     \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_before_zero_grad                                                                                                                     \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_backward                                                                                                                  \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_before_backward                                                                                                                     \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_backward      \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_before_backward                                                                                                                      \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_after_backward                                                                                                                   \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_after_backward                                                                                                                      \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_after_backward       \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_optimizer_step                                                                                                            \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_before_optimizer_step                                                                                                                \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_end                                                                                                                     \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_train_batch_end                                                                                                                      \t|  0.0            \t|  6850           \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_train_epoch_end                                                                                                                      \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningDataModule]CurrencyDataModule.state_dict                                                                                                            \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_save_checkpoint                                                                                                                  \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_save_checkpoint                                                                                                                     \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_save_checkpoint      \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_save_checkpoint                                                                                                                      \t|  0.0            \t|  50             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_end                                                                                                                        \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_end                                                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_end            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_train_end                                                                                                                            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_end                                                                                                                   \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_end                                                                                                                          \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_fit_end                                                                                                                             \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_end              \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_fit_end                                                                                                                              \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningDataModule]CurrencyDataModule.teardown                                                                                                              \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.teardown                                                                                                                            \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.teardown                                                                                                                               \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.teardown                \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.teardown                                                                                                                                \t|  0.0            \t|  2              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningDataModule]CurrencyDataModule.test_dataloader                                                                                                       \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_test_model_eval                                                                                                                      \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_test_start                                                                                                                       \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_test_start                                                                                                                          \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_start           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_test_start                                                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_test_start                                                                                                                  \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_test_epoch_start                                                                                                                 \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_test_epoch_start                                                                                                                    \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_epoch_start     \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_test_epoch_start                                                                                                                     \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_test_batch_start                                                                                                                 \t|  0.0            \t|  59             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_test_batch_start                                                                                                                    \t|  0.0            \t|  59             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_batch_start     \t|  0.0            \t|  59             \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_test_batch_start                                                                                                                     \t|  0.0            \t|  59             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_test_batch_end                                                                                                                      \t|  0.0            \t|  59             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_batch_end       \t|  0.0            \t|  59             \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_test_batch_end                                                                                                                       \t|  0.0            \t|  59             \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_test_epoch_end                                                                                                                   \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_test_epoch_end                                                                                                                      \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_epoch_end       \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_test_epoch_end                                                                                                                       \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_test_end                                                                                                                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_test_end                                                                                                                            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_test_end             \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]LSTM.on_test_end                                                                                                                             \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_test_end                                                                                                                    \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 10685.3388671875}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training some more\n",
    "path_to_best_checkpoint = trainer.checkpoint_callback.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at c:\\Users\\igor\\Documents\\GitHub\\financial_tools\\currency\\lightning\\lightning_logs\\version_10\\checkpoints\\epoch=29-step=8190.ckpt\n",
      "c:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:361: The dirpath has changed from 'c:\\\\Users\\\\igor\\\\Documents\\\\GitHub\\\\financial_tools\\\\currency\\\\lightning\\\\lightning_logs\\\\version_10\\\\checkpoints' to 'c:\\\\Users\\\\igor\\\\Documents\\\\GitHub\\\\financial_tools\\\\currency\\\\lightning\\\\lightning_logs\\\\version_11\\\\checkpoints', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "0 | lstm | LSTM | 18    \n",
      "------------------------------\n",
      "18        Trainable params\n",
      "0         Non-trainable params\n",
      "18        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "Restored all states from the checkpoint at c:\\Users\\igor\\Documents\\GitHub\\financial_tools\\currency\\lightning\\lightning_logs\\version_10\\checkpoints\\epoch=29-step=8190.ckpt\n",
      "c:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 273/273 [00:01<00:00, 259.55it/s, v_num=11]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 273/273 [00:01<00:00, 258.57it/s, v_num=11]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloaders=train_dl, ckpt_path = path_to_best_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: |          | 0/? [01:50<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:864\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[1;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 864\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32mc:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:903\u001b[0m, in \u001b[0;36mTrainer._predict_impl\u001b[1;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    900\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn, ckpt_path, model_provided\u001b[38;5;241m=\u001b[39mmodel_provided, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    902\u001b[0m )\n\u001b[1;32m--> 903\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:987\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    984\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    986\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 987\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    990\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    991\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    992\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1028\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1026\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_loop\u001b[38;5;241m.\u001b[39mrun()\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[1;32m-> 1028\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m   1030\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n",
      "File \u001b[1;32mc:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\loops\\utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\loops\\prediction_loop.py:124\u001b[0m, in \u001b[0;36m_PredictionLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\loops\\prediction_loop.py:253\u001b[0m, in \u001b[0;36m_PredictionLoop._predict_step\u001b[1;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# configure step_kwargs\u001b[39;00m\n\u001b[0;32m    248\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_step\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[0;32m    252\u001b[0m )\n\u001b[1;32m--> 253\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredict_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m predictions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warning_cache\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict returned None if it was on purpose, ignore this warning...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 309\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    312\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32mc:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:438\u001b[0m, in \u001b[0;36mStrategy.predict_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 438\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightning\\pytorch\\core\\module.py:921\u001b[0m, in \u001b[0;36mLightningModule.predict_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[38;5;66;03m# For backwards compatibility\u001b[39;00m\n\u001b[0;32m    920\u001b[0m batch \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m, args[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 11\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m---> 11\u001b[0m   lstm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m   \u001b[38;5;66;03m# [batch_size, 1]\u001b[39;00m\n\u001b[0;32m     14\u001b[0m   last_unrolled_values \u001b[38;5;241m=\u001b[39m lstm_output[\u001b[38;5;241m0\u001b[39m][:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
      "File \u001b[1;32mc:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\igor\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:875\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    873\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 875\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m    876\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM: Expected input to be 2D or 3D, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    877\u001b[0m     is_batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(model, dataloaders=test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | Name   | Type   | Params | In sizes  | Out sizes                          \n",
      "------------------------------------------------------------------------------------\n",
      "0 | lstm   | LSTM   | 16     | [8, 5, 1] | [[8, 5, 1], [[1, 8, 1], [1, 8, 1]]]\n",
      "1 | linear | Linear | 2      | [8, 1]    | [8, 1]                             \n",
      "------------------------------------------------------------------------------------\n",
      "18        Trainable params\n",
      "0         Non-trainable params\n",
      "18        Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.utilities.model_summary import ModelSummary\n",
    "summary = ModelSummary(model, max_depth=-1)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests\n",
    "input = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size=1, hidden_size=1, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_output = lstm(input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 5, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_output[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_unrolled_values = lstm_output[0][:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_unrolled_values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(in_features=1, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_output = linear(last_unrolled_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_output.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
